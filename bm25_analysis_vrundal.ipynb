{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Quick-Introduction-to-Okapi-BM25\" data-toc-modified-id=\"Quick-Introduction-to-Okapi-BM25-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Quick Introduction to Okapi BM25</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gaining-Intuition-for-Okapi-BM25\" data-toc-modified-id=\"Gaining-Intuition-for-Okapi-BM25-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Gaining Intuition for Okapi BM25</a></span></li><li><span><a href=\"#Implementation\" data-toc-modified-id=\"Implementation-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Implementation</a></span></li><li><span><a href=\"#ElasticSearch-BM25\" data-toc-modified-id=\"ElasticSearch-BM25-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>ElasticSearch BM25</a></span></li></ul></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(path)\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import requests\n",
    "import numpy as np \n",
    "import pandas as np \n",
    "import json\n",
    "# 1. magic to print version\n",
    "# 2. magic so that the notebook will reload external python modules\n",
    "# %load_ext watermark\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "# %watermark -a 'Ethen' -d -t -v -p requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Introduction to Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem that **BM25 (Best Match 25)** tries to solve is similar to that of [TFIDF (Term Frequency, Inverse Document Frequency)](http://nbviewer.jupyter.org/github/ethen8181/machine-learning/blob/master/clustering/tfidf/tfidf.ipynb), that is representing our text in a vector space (it can be applied to field outside of text, but text is where it has the biggest presence) so we can search/find similar documents for a given document or query.\n",
    "\n",
    "The gist behind TFIDF is that is relies on two main factors to determine whether a document is similar to our query.\n",
    "\n",
    "- Term Frequency aka tf: how often does the term occur in the document? 3 times? 10 times?\n",
    "- Inverse Document Frequency aka idf: measures how many documents the term appeared in. Inverse document frequency (1/df) then measures how special the term is. Is the term a very rare (occurs in just one doc) word? Or a relatively common one (occurs in nearly all the docs)?\n",
    "\n",
    "Using these two factors, TFIDF measures the relative concentration of a term in a given piece of document. If the term is common in this article, but relatively rare elsewhere, then the TFIDF score will be high, and documents that have higher TFIDF score would be considered as very relevant to the search term.\n",
    "\n",
    "BM25 improves upon TFIDF by casting relevance as a probability problem. A relevance score, according to probabilistic information retrieval, ought to reflect the probability a user will consider the result relevant. Instead of going through how the formula was derived, here we'll take a look a the formula and try to digest it to see why it makes some kind of sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaining Intuition for Okapi BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BM25 (Best Match 25)** function scores each document in a corpus according to the document's relevance to a particular text query. For a query $Q$, with terms $q_1, \\ldots, q_n$, the BM25 score for document $D$ is:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{BM25}(D, Q) = \\sum_{i=1}^n IDF(q_i, D) \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i) + k_1 \\cdot (1-b + b \\cdot |D|/d_{avg}))}\n",
    "\\end{align}\n",
    "\n",
    "where:\n",
    "\n",
    "- $f(q_i, D)$ is the number of times term $q_i$ occurs in document $D$.\n",
    "- $|D|$ is the number of words in document $D$.\n",
    "- $d_{avg}$ is the average number of words per document.\n",
    "- $b$ and $k_1$ are hyperparameters for BM25.\n",
    "\n",
    "Let's break the formula down into smaller components to see why it makes sense.\n",
    "\n",
    "- First of all, there's $f(q_i, D)$ and $k_1$. $f(q_i, D)$ should match our intuition, as this means the more times the query term appears in the document, the higher the document's score will be. The interesting part is the **parameter $k_1$, which determines the term frequency saturation characteristic. The higher the value, the slower the saturation.** And when we say saturation, we are referring to the fact that if terms occurring extra times add extra score. We can observe this diminishing return in term frequency from the graph below.\n",
    "\n",
    "<img src=\"./tf_comparison.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "- Then $|D|/d_{avg}$ part in the denominator means a document that is longer than the average documents will result in a bigger denominator, resulting in a decrease in the score. The intuition is that the more terms in the document that does not match our input query - the lower the document's score should be. In other words, if a 300 page long document mentions the query term once, it's less likely to have as much to do with the query compared to a short tweet which mentions query once.\n",
    "\n",
    "<img src=\"./doc_len_comparison.png\" width=\"70%\" height=\"70%\">\n",
    "\n",
    "From the graph above, we can see that shorter documents hit the asymptote much faster. Hopefully, this resembles our intuition as the more matches we have on shorter documents, the more certain we are about the relevance, whereas, for a lengthy book, it might take us longer to get to a point where we feel confident that the book is indeed relevant to the given query.\n",
    "\n",
    "- The parameter $b$ (bound 0.0 ~ 1.0) in the denominator is multiplied by the ratio of the document length we just discussed. **If $b$ is bigger, the effects of the document length compared to the average length are more amplified.** We can imagine if we set $b$ to 0, the effect of the length ratio would be completely nullified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the inverse document frequency part, ${IDF}(q_i, D)$. For a corpus with $N$ documents, inverse document frequency for term $q_i$ is computed as follows:\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{IDF}(q_i, D) = \\log \\frac{N - N(q_i) + 0.5}{N(q_i) + 0.5}\n",
    "\\end{align}\n",
    "\n",
    "where\n",
    "\n",
    "- $N(q_i)$ is the number of documents in the corpus that contain term $q_i$.\n",
    "\n",
    "The inverse document frequency part is very similar to that of TFIDF, whose role is to make sure that rarer words will have a higher score and contribute more to the final score.\n",
    "\n",
    "Please note that the IDF formula listed above has a drawback when using it for terms appearing in more than half of the corpus since the value would come out as negative value, resulting in the overall score to become negative. e.g. if we have 10 documents in the corpus, and the term \"the\" appeared in 6 of them, its IDF would be $log(10 - 6 + 0.5 / 6 + 0.5) = log(4.5 / 6.5)$. Although we can argue that our implementation should have already removed these frequently appearing words as these words are mostly used to form a complete sentence and carry little meaning of note, different softwares/packages still make different adjustments to prevent a negative score from ever occurring. e.g.\n",
    "\n",
    "- Add a 1 to the equation.\n",
    "\n",
    "\\begin{align}\n",
    "\\mbox{IDF}(q_i) = \\log \\big( 1 + \\frac{N - N(q_i) + 0.5}{N(q_i) + 0.5} \\big)\n",
    "\\end{align}\n",
    "\n",
    "- For term that resulted in a negative IDF value, swap it with an small positive value, usually denoted as $\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like all hyperparameters in general, the default ones are usually a good starting point, and we should probably focus on tweaking other stuff before jumping into the rabbit hole of hyperparameter tuning. In the context of search, it might be making sure our ranking scores older documents lower in application such as news ranking. But if we were to start tuning, remember to always measure the performance of various settings and the following questions are general starting points that we can reference to.\n",
    "\n",
    "- For $k_1$, we should be asking, \"when do we think a term is likely to be saturated?\" For very long documents like books, it's very likely to have a lot of different terms appear several times in a work, even when the term isn't the primary subject of the document. We may not want terms to be saturated as quickly in this situation, so the suggestion is that $k_1$ should generally trend toward larger numbers when the text is a lot longer and more diverse. On the opposite side of things, it's been suggested to set $k_1$ on the lower side. It's very unlikely that a collection of short tweets would have a term multiple times without being highly related to that term.\n",
    "- For $b$, we should be asking, \"when do we think a document is likely to be very long, and when should that hinder its relevance to a term?\" Documents which are highly specific like engineering specifications or patents are lengthy in order to be more specific about a subject. Their length is unlikely to be detrimental to the relevance and lower $b$ may be more appropriate. On the other end of the spectrum, documents which touch on several different topics in a broad way — news articles (a political article may touch on economics, international affairs, and certain corporations), user reviews, etc. — often benefit by choosing a larger $b$ so that irrelevant topics to a user's search, including spam and the like, are penalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vrundalshah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK stopwords (run this line once to download the stopwords)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Assuming 'data' is a list of dictionaries with a 'text' key\n",
    "with open('../test_data/wiki_hard.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "texts = [\n",
    "    [word for word in word_tokenize(str(doc).lower()) if word not in stop_words]\n",
    "    for doc in df['text']\n",
    "]\n",
    "\n",
    "# Now you can use 'df' as a regular pandas DataFrame and 'texts' for processed text\n",
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract text from the loaded data\n",
    "# with open('wiki_hard_test_25-50.pkl', 'rb') as f:\n",
    "#     data = pickle.load(f)\n",
    "    \n",
    "# corpus = [doc['text'] for group in data for doc in group['documents']]\n",
    "\n",
    "# # Preprocess the text (remove stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we'll generate some fake texts to experiment with\n",
    "# corpus = [\n",
    "#     'Human machine interface for lab abc computer applications',\n",
    "#     'A survey of user opinion of computer system response time',\n",
    "#     'The EPS user interface management system',\n",
    "#     'System and human system engineering testing of EPS',\n",
    "#     'Relation of user perceived response time to error measurement',\n",
    "#     'The generation of random binary unordered trees',\n",
    "#     'The intersection graph of paths in trees',\n",
    "#     'Graph minors IV Widths of trees and well quasi ordering',\n",
    "#     'Graph minors A survey'\n",
    "# ]\n",
    "\n",
    "\n",
    "# # remove stop words and tokenize them (we probably want to do some more\n",
    "# # preprocessing with our text in a real world setting, but we'll keep\n",
    "# # it simple here)\n",
    "# stopwords = set(['for', 'a', 'of', 'the', 'and', 'to', 'in'])\n",
    "# texts = [\n",
    "#     [word for word in document.lower().split() if word not in stopwords]\n",
    "#     for document in corpus\n",
    "# ]\n",
    "\n",
    "# build a word count dictionary so we can remove words that appear only once\n",
    "word_count_dict = {}\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        word_count = word_count_dict.get(token, 0) + 1\n",
    "        word_count_dict[token] = word_count\n",
    "\n",
    "texts = [[token for token in text if word_count_dict[token] > 1] for text in texts]\n",
    "# texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    \"\"\"\n",
    "    Best Match 25.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k1 : float, default 1.5\n",
    "\n",
    "    b : float, default 0.75\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    tf_ : list[dict[str, int]]\n",
    "        Term Frequency per document. So [{'hi': 1}] means\n",
    "        the first document contains the term 'hi' 1 time.\n",
    "\n",
    "    df_ : dict[str, int]\n",
    "        Document Frequency per term. i.e. Number of documents in the\n",
    "        corpus that contains the term.\n",
    "\n",
    "    idf_ : dict[str, float]\n",
    "        Inverse Document Frequency per term.\n",
    "\n",
    "    doc_len_ : list[int]\n",
    "        Number of terms per document. So [3] means the first\n",
    "        document contains 3 terms.\n",
    "\n",
    "    corpus_ : list[list[str]]\n",
    "        The input corpus.\n",
    "\n",
    "    corpus_size_ : int\n",
    "        Number of documents in the corpus.\n",
    "\n",
    "    avg_doc_len_ : float\n",
    "        Average number of terms for documents in the corpus.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        \"\"\"\n",
    "        Fit the various statistics that are required to calculate BM25 ranking\n",
    "        score using the corpus given.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        corpus : list[list[str]]\n",
    "            Each element in the list represents a document, and each document\n",
    "            is a list of the terms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        tf = []\n",
    "        df = {}\n",
    "        idf = {}\n",
    "        doc_len = []\n",
    "        corpus_size = 0\n",
    "        for document in corpus:\n",
    "            corpus_size += 1\n",
    "            doc_len.append(len(document))\n",
    "\n",
    "            # compute tf (term frequency) per document\n",
    "            frequencies = {}\n",
    "            for term in document:\n",
    "                term_count = frequencies.get(term, 0) + 1\n",
    "                frequencies[term] = term_count\n",
    "\n",
    "            tf.append(frequencies)\n",
    "\n",
    "            # compute df (document frequency) per term\n",
    "            for term, _ in frequencies.items():\n",
    "                df_count = df.get(term, 0) + 1\n",
    "                df[term] = df_count\n",
    "\n",
    "        for term, freq in df.items():\n",
    "            idf[term] = math.log(1 + (corpus_size - freq + 0.5) / (freq + 0.5))\n",
    "\n",
    "        self.tf_ = tf\n",
    "        self.df_ = df\n",
    "        self.idf_ = idf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.corpus_ = corpus\n",
    "        self.corpus_size_ = corpus_size\n",
    "        self.avg_doc_len_ = sum(doc_len) / corpus_size\n",
    "        return self\n",
    "\n",
    "    def search(self, query):\n",
    "        scores = [self._score(query, index) for index in range(self.corpus_size_)]\n",
    "        return scores\n",
    "\n",
    "    def _score(self, query, index):\n",
    "        score = 0.0\n",
    "\n",
    "        doc_len = self.doc_len_[index]\n",
    "        frequencies = self.tf_[index]\n",
    "        for term in query:\n",
    "            if term not in frequencies:\n",
    "                continue\n",
    "\n",
    "            freq = frequencies[term]\n",
    "            numerator = self.idf_[term] * freq * (self.k1 + 1)\n",
    "            denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.avg_doc_len_)\n",
    "            score += (numerator / denominator)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np \n",
    "\n",
    "# # 1. Initialize and Fit BM25\n",
    "# bm25 = BM25(k1=2.5, b=0.55)\n",
    "\n",
    "# bm25.fit(texts)  # Assuming 'texts' is your corpus\n",
    "\n",
    "# # 2. Compare Similarity Between Texts\n",
    "# num_texts = len(texts)\n",
    "# similarity_matrix = np.zeros((num_texts, num_texts))\n",
    "\n",
    "# for i in range(num_texts):\n",
    "#     for j in range(i + 1, num_texts):  # Avoid redundant comparisons\n",
    "#         # if i <1:\n",
    "#             # print(texts[j+2])\n",
    "#             # # print(i)\n",
    "            \n",
    "#         # Compute BM25 similarity score between texts i and j\n",
    "#         score_ij = bm25._score(texts[j], i)\n",
    "#         similarity_matrix[i, j] = score_ij\n",
    "#         similarity_matrix[j, i] = score_ij  # Symmetric matrix\n",
    "\n",
    "# # # Optionally, print or analyze the similarity matrix\n",
    "# # print(\"BM25 Similarity Matrix:\")\n",
    "# # print(similarity_matrix)\n",
    "\n",
    "# plt.title(\"Normalized Similarily Heatmap using BM25\")\n",
    "\n",
    "# # Normalize the similarity matrix\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized_matrix = scaler.fit_transform(similarity_matrix)\n",
    "# # Plot the heatmap\n",
    "# sns.heatmap(normalized_matrix, cmap=\"YlGnBu\", xticklabels=False, yticklabels=False)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import jaccard_score\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1. Compare Similarity Between Texts using Jaccard Similarity\n",
    "# num_texts = len(texts)\n",
    "# similarity_matrix = np.zeros((num_texts, num_texts))\n",
    "\n",
    "# for i in range(num_texts):\n",
    "#     for j in range(i + 1, num_texts):  \n",
    "#         set_i = set(texts[i])\n",
    "#         set_j = set(texts[j])\n",
    "        \n",
    "#         # Take the intersection of the sets\n",
    "#         intersection = set_i.intersection(set_j)\n",
    "#         union = set_i.union(set_j)\n",
    "        \n",
    "#         # Calculate Jaccard similarity\n",
    "#         if len(union) > 0:\n",
    "#             score_ij = len(intersection) / len(union)\n",
    "#         else:\n",
    "#             score_ij = 0.0\n",
    "        \n",
    "#         similarity_matrix[i, j] = score_ij\n",
    "#         similarity_matrix[j, i] = score_ij  # Symmetric matrix\n",
    "\n",
    "# # Normalize the similarity matrix\n",
    "# scaler = MinMaxScaler()\n",
    "# normalized_matrix = scaler.fit_transform(similarity_matrix)\n",
    "# # Plot the heatmap\n",
    "# sns.heatmap(normalized_matrix, cmap=\"YlGnBu\", xticklabels=False, yticklabels=False)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # Apply PCA for dimensionality reduction\n",
    "# pca = PCA(n_components=2)\n",
    "# reduced_matrix = pca.fit_transform(normalized_matrix)\n",
    "\n",
    "# # Scatter plot of reduced matrix\n",
    "# plt.scatter(reduced_matrix[:, 0], reduced_matrix[:, 1])\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some utility functions for text processing.\n",
    "\"\"\"\n",
    "import random\n",
    "\n",
    "def split_text(text, chunk_size, overlap):\n",
    "    \"\"\"\n",
    "    Splits text into a list of chunks of some size with some overlap.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "\n",
    "    if overlap > chunk_size:\n",
    "        overlap = chunk_size\n",
    "    \n",
    "    for i in range(0, len(words)-chunk_size+1, chunk_size-overlap):\n",
    "        chunk = ' '.join(words[i:i+chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def get_random_query(text, min_len, max_len, n_samples):\n",
    "    \"\"\"\n",
    "    Given some text, generate a number of random substring of size ranging [min_len, max_len].\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "\n",
    "    if min_len > max_len or min_len < 1:\n",
    "        raise ValueError(\"Invalid size parameters.\")\n",
    "    if max_len > len(words):\n",
    "        raise ValueError(\"Max size length too large.\")\n",
    "\n",
    "    queries = []\n",
    "    # generate random samples\n",
    "    for i in range(n_samples):\n",
    "        # get random index to look at\n",
    "        query_len = random.randint(min_len, max_len)\n",
    "        rand_idx = random.randint(0, len(words) - query_len)\n",
    "\n",
    "        query = ' '.join(words[rand_idx : rand_idx+query_len])\n",
    "        queries.append(query)\n",
    "\n",
    "    return queries\n",
    "\n",
    "def explode_list(some_list):\n",
    "    \"\"\"\n",
    "    Explode a list of lists to one list.\n",
    "    \"\"\"\n",
    "    return [x for sublist in some_list for x in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Load the query data\n",
    "# with open(\"./test_data/wiki_hard_test_25-50.pkl\", \"rb\") as file:\n",
    "#     query_file = pickle.load(file)\n",
    "\n",
    "# query_df = pd.DataFrame(query_file)\n",
    "\n",
    "# # Example: Extracting text from the DataFrame and removing stopwords\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# queries = [\n",
    "#     [word for word in word_tokenize(str(doc).lower()) if word not in stop_words]\n",
    "#     for doc in query_df['text']\n",
    "# ]\n",
    "\n",
    "# bm25 = BM25()\n",
    "# bm25.fit(texts)\n",
    "# scores = [bm25.search(query) for query in queries]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# for query, score_list in zip(queries, scores):\n",
    "#     for score, doc in zip(score_list, texts):  # Using 'texts' after tokenization\n",
    "#         score = round(score, 3)\n",
    "#         snippet = ' '.join(doc)\n",
    "#         # Append results to the list\n",
    "#         results.append({\n",
    "#             'query': query,\n",
    "#             'score': score,\n",
    "#             'snippet': snippet,\n",
    "#         })\n",
    "\n",
    "# results_df = pd.DataFrame(results)\n",
    "# print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.histplot(results_df['score'], bins=20, kde=True)\n",
    "# plt.title('Distribution of BM25 Scores')\n",
    "# plt.xlabel('BM25 Score')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define aux search function\n",
    "bm25 = BM25()\n",
    "bm25.fit(texts)\n",
    "def searchAux(query):\n",
    "    # Query\n",
    "    query = query\n",
    "\n",
    "    # Get scores for the query\n",
    "    scores = bm25.search(query)\n",
    "\n",
    "    # Combine scores with documents\n",
    "    results = list(zip(scores, bm25.corpus_))\n",
    "\n",
    "    # Sort results by score in descending order\n",
    "    sorted_results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # Display sorted results\n",
    "    for score, doc in sorted_results:\n",
    "        score = round(score, 3)\n",
    "        snippet = ' '.join(doc[:10])  # Displaying the first 10 tokens\n",
    "        print(str(score) + '\\t' + snippet + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.757\tcomputer science , radix sort sorting algorithm . avoids comparison...\n",
      "18.342\tcomputer science , merge sort ( also commonly spelled mergesort...\n",
      "17.533\tlabrador retriever labrador british breed retriever gun dog . developed...\n",
      "16.044\tspaghetti ( ) long , thin , solid , cylindrical...\n",
      "15.47\tbattle fort sumter ( april 12–13 , 1861 ) bombardment...\n",
      "13.147\tinsertion sort simple sorting algorithm builds final sorted array (...\n",
      "11.371\tquicksort in-place sorting algorithm . developed british computer scientist tony...\n",
      "10.493\tamazon river ( , ; , ) south america largest...\n",
      "8.903\tbubble sort , sometimes referred sinking sort , simple sorting...\n",
      "8.763\tbucket sort , bin sort , sorting algorithm works distributing...\n",
      "6.511\ttree sort sort algorithm builds binary search tree elements sorted...\n",
      "5.672\tcomputer science , selection sort in-place comparison sorting algorithm ....\n",
      "5.658\tnile major river northeastern africa . flows mediterranean sea ....\n",
      "5.473\tbattle atlanta battle atlanta campaign fought american civil war july...\n",
      "4.914\tphở pho ( , , ; ) vietnamese soup dish...\n",
      "3.759\twelsh corgi ( corgi , plural corgis , occasionally consistent...\n",
      "3.498\tzhou dynasty ( ; old chinese ( b & )...\n",
      "3.425\tandrew jackson ( march 15 , 1767 – june 8...\n",
      "3.293\tbeagle breed small scent hound , similar appearance much larger...\n",
      "3.068\tganges ( ) ( india : ganga ( ) ;...\n",
      "1.991\than dynasty ( ) second imperial dynasty china ( 202...\n",
      "1.956\tjohn tyler ( march 29 , 18 , 1862 )...\n",
      "1.783\tyangtze , yangzi ( ) , officially chang jiang longest...\n",
      "1.612\triver thames ( ) , known alternatively parts river isis...\n",
      "0.0\tgeorge washington ( february 22 , 1732 , 1799 )...\n",
      "0.0\tjohn quincy adams ( ; july 11 , 1767 –...\n",
      "0.0\tjames madison jr. ( march 16 , 28 , 1836...\n",
      "0.0\tjames monroe ( ; april 28 , 4 , 1831...\n",
      "0.0\tmartin van buren ( ; born maarten van buren (...\n",
      "0.0\tthomas jefferson ( april 13 , 1743 – july 4...\n",
      "0.0\twilliam henry harrison ( february 9 , 4 , 1841...\n",
      "0.0\tjohn adams ( october 30 , 1735 – july 4...\n",
      "0.0\tqing dynasty , officially great qing ( ) , last...\n",
      "0.0\tming dynasty ( ) , officially great ming , ruling...\n",
      "0.0\ttang dynasty ( , ; ) , tang empire ,...\n",
      "0.0\tsui dynasty ( , ) short-lived imperial dynasty china pivotal...\n",
      "0.0\tqin dynasty , dynasty wade–giles romanization , first dynasty imperial...\n",
      "0.0\tshang dynasty ( ) , also historically known yin dynasty...\n",
      "0.0\tsong dynasty ( ; ; 960–1279 ) imperial dynasty china...\n",
      "0.0\tyuan dynasty ( ) , officially great yuan ( ;...\n",
      "0.0\teuphrates ( ) longest one historically important rivers western asia...\n",
      "0.0\tmississippi river second-longest river chief river second-largest drainage system north...\n",
      "0.0\ttigris ( ) two great rivers define mesopotamia , euphrates...\n",
      "0.0\tyellow river huang ( chinese : , mandarin : hé...\n",
      "0.0\tmekong mekong river trans-boundary river east asia southeast asia ....\n",
      "0.0\tcomputer science , heapsort comparison-based sorting algorithm . heapsort thought...\n",
      "0.0\tcomputer science , counting sort algorithm sorting collection objects according...\n",
      "0.0\tjapanese noodle soup . consists chinese-style wheat noodles served meat...\n",
      "0.0\tudon ( ) thick noodle made wheat flour , used...\n",
      "0.0\tpad thai , phat thai , thai ( ; ,...\n",
      "0.0\tyakisoba ( ) , `` fried noodle '' , japanese...\n",
      "0.0\tpancit ( ) , also spelled pansít , general term...\n",
      "0.0\tjapchae ( ) savory slightly sweet dish stir-fried glass noodles...\n",
      "0.0\tjajangmyeon ( ) jjajangmyeon ( ) korean noodle dish topped...\n",
      "0.0\tliangpi ( ) chinese dish made wheat rice flour ....\n",
      "0.0\tbreed hunting dog japan . breed , smallest six original...\n",
      "0.0\tgerman shepherd german shepherd dog , also known alsatian ,...\n",
      "0.0\tpomeranian ( often known ) breed dog spitz type named...\n",
      "0.0\tbulldog , also known english bulldog british bulldog , medium-sized...\n",
      "0.0\trottweiler ( , ) breed domestic dog , regarded large...\n",
      "0.0\tpoodle , called pudel german caniche french , breed water...\n",
      "0.0\tgolden retriever british breed retriever dog medium size . characterised...\n",
      "0.0\tbattle gettysburg ( ) fought july 1–3 , 1863 ,...\n",
      "0.0\tbattle chancellorsville major battle american civil war ( 1861–1865 )...\n",
      "0.0\tbattle antietam ( ) , battle sharpsburg particularly southern united...\n",
      "0.0\tbattle shiloh ( also known battle pittsburg landing ) early...\n",
      "0.0\tbattle chickamauga , fought september 18–20 , 1863 , u.s....\n",
      "0.0\tfirst battle bull run ( name used union forces )...\n",
      "0.0\tsiege vicksburg ( may 18 – july 4 , 1863...\n",
      "0.0\tbattle appomattox court house , fought appomattox county , virginia...\n"
     ]
    }
   ],
   "source": [
    "searchAux('Types of Chinese noodles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.31\tcomputer science , merge sort ( also commonly spelled mergesort...\n",
      "32.031\tcomputer science , radix sort sorting algorithm . avoids comparison...\n",
      "18.171\tinsertion sort simple sorting algorithm builds final sorted array (...\n",
      "17.355\tbubble sort , sometimes referred sinking sort , simple sorting...\n",
      "16.641\tbucket sort , bin sort , sorting algorithm works distributing...\n",
      "15.158\tquicksort in-place sorting algorithm . developed british computer scientist tony...\n",
      "12.538\tbattle atlanta battle atlanta campaign fought american civil war july...\n",
      "8.966\ttree sort sort algorithm builds binary search tree elements sorted...\n",
      "8.016\tcomputer science , selection sort in-place comparison sorting algorithm ....\n",
      "7.838\than dynasty ( ) second imperial dynasty china ( 202...\n",
      "7.601\tjapanese noodle soup . consists chinese-style wheat noodles served meat...\n",
      "7.113\tphở pho ( , , ; ) vietnamese soup dish...\n",
      "6.092\tjohn tyler ( march 29 , 18 , 1862 )...\n",
      "4.72\tganges ( ) ( india : ganga ( ) ;...\n",
      "3.865\triver thames ( ) , known alternatively parts river isis...\n",
      "3.566\tbattle antietam ( ) , battle sharpsburg particularly southern united...\n",
      "3.456\trottweiler ( , ) breed domestic dog , regarded large...\n",
      "2.935\tlabrador retriever labrador british breed retriever gun dog . developed...\n",
      "2.323\tspaghetti ( ) long , thin , solid , cylindrical...\n",
      "2.071\tming dynasty ( ) , officially great ming , ruling...\n",
      "1.988\tandrew jackson ( march 15 , 1767 – june 8...\n",
      "1.897\tzhou dynasty ( ; old chinese ( b & )...\n",
      "1.881\teuphrates ( ) longest one historically important rivers western asia...\n",
      "1.758\tbeagle breed small scent hound , similar appearance much larger...\n",
      "1.739\ttang dynasty ( , ; ) , tang empire ,...\n",
      "1.736\tgerman shepherd german shepherd dog , also known alsatian ,...\n",
      "1.325\tsong dynasty ( ; ; 960–1279 ) imperial dynasty china...\n",
      "1.054\tqing dynasty , officially great qing ( ) , last...\n",
      "0.0\tgeorge washington ( february 22 , 1732 , 1799 )...\n",
      "0.0\tjohn quincy adams ( ; july 11 , 1767 –...\n",
      "0.0\tjames madison jr. ( march 16 , 28 , 1836...\n",
      "0.0\tjames monroe ( ; april 28 , 4 , 1831...\n",
      "0.0\tmartin van buren ( ; born maarten van buren (...\n",
      "0.0\tthomas jefferson ( april 13 , 1743 – july 4...\n",
      "0.0\twilliam henry harrison ( february 9 , 4 , 1841...\n",
      "0.0\tjohn adams ( october 30 , 1735 – july 4...\n",
      "0.0\tsui dynasty ( , ) short-lived imperial dynasty china pivotal...\n",
      "0.0\tqin dynasty , dynasty wade–giles romanization , first dynasty imperial...\n",
      "0.0\tshang dynasty ( ) , also historically known yin dynasty...\n",
      "0.0\tyuan dynasty ( ) , officially great yuan ( ;...\n",
      "0.0\tamazon river ( , ; , ) south america largest...\n",
      "0.0\tyangtze , yangzi ( ) , officially chang jiang longest...\n",
      "0.0\tmississippi river second-longest river chief river second-largest drainage system north...\n",
      "0.0\tnile major river northeastern africa . flows mediterranean sea ....\n",
      "0.0\ttigris ( ) two great rivers define mesopotamia , euphrates...\n",
      "0.0\tyellow river huang ( chinese : , mandarin : hé...\n",
      "0.0\tmekong mekong river trans-boundary river east asia southeast asia ....\n",
      "0.0\tcomputer science , heapsort comparison-based sorting algorithm . heapsort thought...\n",
      "0.0\tcomputer science , counting sort algorithm sorting collection objects according...\n",
      "0.0\tudon ( ) thick noodle made wheat flour , used...\n",
      "0.0\tpad thai , phat thai , thai ( ; ,...\n",
      "0.0\tyakisoba ( ) , `` fried noodle '' , japanese...\n",
      "0.0\tpancit ( ) , also spelled pansít , general term...\n",
      "0.0\tjapchae ( ) savory slightly sweet dish stir-fried glass noodles...\n",
      "0.0\tjajangmyeon ( ) jjajangmyeon ( ) korean noodle dish topped...\n",
      "0.0\tliangpi ( ) chinese dish made wheat rice flour ....\n",
      "0.0\tbreed hunting dog japan . breed , smallest six original...\n",
      "0.0\tpomeranian ( often known ) breed dog spitz type named...\n",
      "0.0\tbulldog , also known english bulldog british bulldog , medium-sized...\n",
      "0.0\twelsh corgi ( corgi , plural corgis , occasionally consistent...\n",
      "0.0\tpoodle , called pudel german caniche french , breed water...\n",
      "0.0\tgolden retriever british breed retriever dog medium size . characterised...\n",
      "0.0\tbattle gettysburg ( ) fought july 1–3 , 1863 ,...\n",
      "0.0\tbattle chancellorsville major battle american civil war ( 1861–1865 )...\n",
      "0.0\tbattle shiloh ( also known battle pittsburg landing ) early...\n",
      "0.0\tbattle chickamauga , fought september 18–20 , 1863 , u.s....\n",
      "0.0\tfirst battle bull run ( name used union forces )...\n",
      "0.0\tsiege vicksburg ( may 18 – july 4 , 1863...\n",
      "0.0\tbattle fort sumter ( april 12–13 , 1861 ) bombardment...\n",
      "0.0\tbattle appomattox court house , fought appomattox county , virginia...\n"
     ]
    }
   ],
   "source": [
    "searchAux('Information on bull dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.601\tjapanese noodle soup . consists chinese-style wheat noodles served meat...\n",
      "5.727\tcomputer science , radix sort sorting algorithm . avoids comparison...\n",
      "3.711\than dynasty ( ) second imperial dynasty china ( 202...\n",
      "0.0\tandrew jackson ( march 15 , 1767 – june 8...\n",
      "0.0\tgeorge washington ( february 22 , 1732 , 1799 )...\n",
      "0.0\tjohn quincy adams ( ; july 11 , 1767 –...\n",
      "0.0\tjames madison jr. ( march 16 , 28 , 1836...\n",
      "0.0\tjames monroe ( ; april 28 , 4 , 1831...\n",
      "0.0\tmartin van buren ( ; born maarten van buren (...\n",
      "0.0\tthomas jefferson ( april 13 , 1743 – july 4...\n",
      "0.0\twilliam henry harrison ( february 9 , 4 , 1841...\n",
      "0.0\tjohn adams ( october 30 , 1735 – july 4...\n",
      "0.0\tjohn tyler ( march 29 , 18 , 1862 )...\n",
      "0.0\tqing dynasty , officially great qing ( ) , last...\n",
      "0.0\tming dynasty ( ) , officially great ming , ruling...\n",
      "0.0\ttang dynasty ( , ; ) , tang empire ,...\n",
      "0.0\tsui dynasty ( , ) short-lived imperial dynasty china pivotal...\n",
      "0.0\tqin dynasty , dynasty wade–giles romanization , first dynasty imperial...\n",
      "0.0\tzhou dynasty ( ; old chinese ( b & )...\n",
      "0.0\tshang dynasty ( ) , also historically known yin dynasty...\n",
      "0.0\tsong dynasty ( ; ; 960–1279 ) imperial dynasty china...\n",
      "0.0\tyuan dynasty ( ) , officially great yuan ( ;...\n",
      "0.0\tamazon river ( , ; , ) south america largest...\n",
      "0.0\tyangtze , yangzi ( ) , officially chang jiang longest...\n",
      "0.0\teuphrates ( ) longest one historically important rivers western asia...\n",
      "0.0\tganges ( ) ( india : ganga ( ) ;...\n",
      "0.0\tmississippi river second-longest river chief river second-largest drainage system north...\n",
      "0.0\tnile major river northeastern africa . flows mediterranean sea ....\n",
      "0.0\ttigris ( ) two great rivers define mesopotamia , euphrates...\n",
      "0.0\triver thames ( ) , known alternatively parts river isis...\n",
      "0.0\tyellow river huang ( chinese : , mandarin : hé...\n",
      "0.0\tmekong mekong river trans-boundary river east asia southeast asia ....\n",
      "0.0\tcomputer science , heapsort comparison-based sorting algorithm . heapsort thought...\n",
      "0.0\tinsertion sort simple sorting algorithm builds final sorted array (...\n",
      "0.0\tcomputer science , merge sort ( also commonly spelled mergesort...\n",
      "0.0\tcomputer science , selection sort in-place comparison sorting algorithm ....\n",
      "0.0\tbucket sort , bin sort , sorting algorithm works distributing...\n",
      "0.0\tcomputer science , counting sort algorithm sorting collection objects according...\n",
      "0.0\tquicksort in-place sorting algorithm . developed british computer scientist tony...\n",
      "0.0\ttree sort sort algorithm builds binary search tree elements sorted...\n",
      "0.0\tbubble sort , sometimes referred sinking sort , simple sorting...\n",
      "0.0\tspaghetti ( ) long , thin , solid , cylindrical...\n",
      "0.0\tudon ( ) thick noodle made wheat flour , used...\n",
      "0.0\tpad thai , phat thai , thai ( ; ,...\n",
      "0.0\tyakisoba ( ) , `` fried noodle '' , japanese...\n",
      "0.0\tphở pho ( , , ; ) vietnamese soup dish...\n",
      "0.0\tpancit ( ) , also spelled pansít , general term...\n",
      "0.0\tjapchae ( ) savory slightly sweet dish stir-fried glass noodles...\n",
      "0.0\tjajangmyeon ( ) jjajangmyeon ( ) korean noodle dish topped...\n",
      "0.0\tliangpi ( ) chinese dish made wheat rice flour ....\n",
      "0.0\tbeagle breed small scent hound , similar appearance much larger...\n",
      "0.0\tbreed hunting dog japan . breed , smallest six original...\n",
      "0.0\tlabrador retriever labrador british breed retriever gun dog . developed...\n",
      "0.0\tgerman shepherd german shepherd dog , also known alsatian ,...\n",
      "0.0\tpomeranian ( often known ) breed dog spitz type named...\n",
      "0.0\tbulldog , also known english bulldog british bulldog , medium-sized...\n",
      "0.0\twelsh corgi ( corgi , plural corgis , occasionally consistent...\n",
      "0.0\trottweiler ( , ) breed domestic dog , regarded large...\n",
      "0.0\tpoodle , called pudel german caniche french , breed water...\n",
      "0.0\tgolden retriever british breed retriever dog medium size . characterised...\n",
      "0.0\tbattle gettysburg ( ) fought july 1–3 , 1863 ,...\n",
      "0.0\tbattle chancellorsville major battle american civil war ( 1861–1865 )...\n",
      "0.0\tbattle antietam ( ) , battle sharpsburg particularly southern united...\n",
      "0.0\tbattle shiloh ( also known battle pittsburg landing ) early...\n",
      "0.0\tbattle atlanta battle atlanta campaign fought american civil war july...\n",
      "0.0\tbattle chickamauga , fought september 18–20 , 1863 , u.s....\n",
      "0.0\tfirst battle bull run ( name used union forces )...\n",
      "0.0\tsiege vicksburg ( may 18 – july 4 , 1863...\n",
      "0.0\tbattle fort sumter ( april 12–13 , 1861 ) bombardment...\n",
      "0.0\tbattle appomattox court house , fought appomattox county , virginia...\n"
     ]
    }
   ],
   "source": [
    "searchAux('dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code chunk above, we printed each corpus's BM25 relevance score along with the original text, note that this isn't sorted in decreasing order of the relevance score yet, which is usually what we want to do in a real world setting. That is to find the more relevant document, sort them in decreasing order and present them to the user. Also here, we are computing the scores for every document, this becomes computationally expensive when we start have a large corpus size. Thus search engine uses **inverted index** to speed things up. An inverted index consists of a list of all the unique words that appear in any document, and for each word, a list of the documents in which it appears, this allows us to quickly find the documents that contains the term in our query and only then do we compute the relevance score for this smaller recall set. This [link](https://www.elastic.co/guide/en/elasticsearch/guide/master/inverted-index.html) contains a good high level description of this concept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticSearch BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see BM25 in action to rank documents using ElasticSearch, this notebook isn't an ElasticSearch tutorial, so hopefully, the reader are some what familiar with the tool, if not, each code chunk contains links to some helpful references.\n",
    "\n",
    "We will follow the standard process of creating the index to store our documents, add some sample documents to the index and provide a query against the index to return the relevant documents sorted in decreasing order based on the relevance score, which will be based on BM25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import requests\n",
    "\n",
    "# # Elasticsearch settings\n",
    "# settings = {\n",
    "#     'settings': {\n",
    "#         'index': {\n",
    "#             'number_of_shards': 1,\n",
    "#             'number_of_replicas': 1,\n",
    "#             'similarity': {\n",
    "#                 'default': {\n",
    "#                     'type': 'BM25'\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     },\n",
    "#     'mappings': {\n",
    "#         '_doc': {\n",
    "#             'properties': {\n",
    "#                 'title': {\n",
    "#                     'type': 'text',\n",
    "#                     'analyzer': 'english'\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # Elasticsearch server URL\n",
    "# url = 'http://localhost:9200/experiment'\n",
    "\n",
    "# # Headers for the request\n",
    "# headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# # Try connecting to Elasticsearch\n",
    "# try:\n",
    "#     response = requests.put(url, data=json.dumps(settings), headers=headers)\n",
    "#     print(response.text)\n",
    "# except requests.ConnectionError as e:\n",
    "#     print(f\"ConnectionError: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # indexing document\n",
    "# # https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html\n",
    "# # https://www.elastic.co/guide/en/elasticsearch/guide/master/index-doc.html\n",
    "\n",
    "# # a document is uniquely identified by the index, the type and id\n",
    "# # it's worth noting that there's a note on removing the capabilities of\n",
    "# # having multiple types under one index, and going forward the type will\n",
    "# # just to set to '_doc'\n",
    "# # https://www.elastic.co/guide/en/elasticsearch/reference/current/removal-of-types.html\n",
    "# url = 'http://localhost:9200/experiment/_doc'\n",
    "\n",
    "# for document in corpus:\n",
    "#     # we insert the document into the 'title' field\n",
    "#     data = {'title': document}\n",
    "#     response = requests.post(url, data=json.dumps(data), headers=headers)\n",
    "    \n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search(query, headers):\n",
    "#     url = 'http://localhost:9200/experiment/_doc/_search'\n",
    "#     response = requests.get(url, data=json.dumps(query), headers=headers)\n",
    "    \n",
    "#     # the response contains other information, such as time it took to\n",
    "#     # give the response back, here we are only interested in the matched\n",
    "#     # results, which are stored under 'hits'\n",
    "#     search_hits = json.loads(response.text)['hits']['hits']\n",
    "\n",
    "#     print('Num\\tRelevance Score\\tTitle')\n",
    "#     for idx, hit in enumerate(search_hits):\n",
    "#         print('%s\\t%s\\t%s' % (idx + 1, hit['_score'], hit['_source']['title']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # match query\n",
    "# # https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-match-query.html\n",
    "# query = {\n",
    "#     'query': {\n",
    "#         'match': {\n",
    "#             # search against the 'title' field\n",
    "#             'title': 'The intersection of graph survey and trees'\n",
    "#         }\n",
    "#     }\n",
    "# }\n",
    "# search(query, headers={'Content-Type': 'application/json'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we can delete this experimental index to prevent occupying space\n",
    "# response = requests.delete('http://localhost:9200/experiment')\n",
    "# response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Wiki: Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)\n",
    "- [Blog: BM25 The Next Generation of Lucene Relevance](https://opensourceconnections.com/blog/2015/10/16/bm25-the-next-generation-of-lucene-relevation/)\n",
    "- [Blog: Practical BM25 - Part 1: How Shards Affect Relevance Scoring in Elasticsearch](https://www.elastic.co/blog/practical-bm25-part-1-how-shards-affect-relevance-scoring-in-elasticsearch)\n",
    "- [Blog: Practical BM25 - Part 2: The BM25 Algorithm and its Variables](https://www.elastic.co/blog/practical-bm25-part-2-the-bm25-algorithm-and-its-variables)\n",
    "- [Blog: Practical BM25 - Part 3: Considerations for Picking b and k1 in Elasticsearch](https://www.elastic.co/blog/practical-bm25-part-3-considerations-for-picking-b-and-k1-in-elasticsearch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
